{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish0604-AK/Deforestation-Analysis-Using-Satellite-Imagery-/blob/main/Deforestion_Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8994f4d",
      "metadata": {
        "id": "d8994f4d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# !pip install rasterio\n",
        "# import rasterio as rio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score , classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sANUbwpT4_g3",
        "outputId": "90862232-1131-48e8-c34c-af665b2d4c69"
      },
      "id": "sANUbwpT4_g3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66bc2e2f",
      "metadata": {
        "id": "66bc2e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad53f56-9613-47c5-e362-92382f3746a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                           Filename  Label  \\\n",
            "0           16257                      AnnualCrop/AnnualCrop_142.jpg      0   \n",
            "1            3297  HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
            "2           17881               PermanentCrop/PermanentCrop_1073.jpg      6   \n",
            "3            2223                      Industrial/Industrial_453.jpg      4   \n",
            "4            4887  HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
            "...           ...                                                ...    ...   \n",
            "18895        4498  HerbaceousVegetation/HerbaceousVegetation_1952...      2   \n",
            "18896        1149                           Pasture/Pasture_1252.jpg      5   \n",
            "18897       15489                     AnnualCrop/AnnualCrop_2332.jpg      0   \n",
            "18898        6287                    Residential/Residential_332.jpg      7   \n",
            "18899       18613                PermanentCrop/PermanentCrop_856.jpg      6   \n",
            "\n",
            "                  ClassName  \n",
            "0                AnnualCrop  \n",
            "1      HerbaceousVegetation  \n",
            "2             PermanentCrop  \n",
            "3                Industrial  \n",
            "4      HerbaceousVegetation  \n",
            "...                     ...  \n",
            "18895  HerbaceousVegetation  \n",
            "18896               Pasture  \n",
            "18897            AnnualCrop  \n",
            "18898           Residential  \n",
            "18899         PermanentCrop  \n",
            "\n",
            "[18900 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "csv_path = os.path.join(data_dir, \"train.csv\")\n",
        "train_csv = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/train.csv\"\n",
        "# test_csv  = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/test.csv\"\n",
        "# val_csv   = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/validate.csv\"\n",
        "\n",
        "df = pd.read_csv(train_csv)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SRtrwOu48Gr"
      },
      "id": "6SRtrwOu48Gr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "forest_path = os.path.join(data_dir, \"Forest\", img_rel)\n",
        "deforest_path = os.path.join(data_dir, \"Deforested\", img_rel)\n",
        "\n",
        "df['BinaryLabel'] = df['ClassName'].apply(\n",
        "    lambda x: 0 if x == \"Forest\" else 1\n",
        ")\n",
        "\n",
        "# Using CNN preinstaled feature extractoe\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = base_model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    img_rel = row['Filename']\n",
        "\n",
        "\n",
        "\n",
        "    if os.path.exists(forest_path):\n",
        "        img_path = forest_path\n",
        "    elif os.path.exists(deforest_path):\n",
        "        img_path = deforest_path\n",
        "    else:\n",
        "        print(\"Missing:\", img_rel)\n",
        "        continue\n",
        "    feat = extract_features(img_path)\n",
        "    X.append(feat)\n",
        "    y.append(row['Label'])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "zQ6Cm5fLcSF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368726ed-7b6d-41a4-f908-4692f9c9cd54"
      },
      "id": "zQ6Cm5fLcSF_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2908700203.py:14: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (18900, 1280)\n",
            "Labels shape: (18900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input"
      ],
      "metadata": {
        "id": "XRim5J8k8Y36"
      },
      "id": "XRim5J8k8Y36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/EuroSAT\"\n",
        "\n",
        "# Binary labels: 0=Forest, 1=Deforested\n",
        "df['BinaryLabel'] = df['ClassName'].apply(lambda x: 0 if x == \"Forest\" else 1)\n",
        "\n",
        "# Here we are reducing dataset\n",
        "df = df.sample(2000, random_state=42).reset_index(drop=True)\n",
        "print(\"Using subset size:\", len(df))\n",
        "\n",
        "\n",
        "#  Feature extraction going on\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return base_model.predict(x, verbose=0).flatten()\n",
        "\n",
        "\n",
        "#looping through rows\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    img_rel = row['Filename']\n",
        "\n",
        "    # Fixing  path logic: don't duplicate \"Forest\"\n",
        "    if row['ClassName'] == \"Forest\":\n",
        "        img_path = os.path.join(data_dir, img_rel)\n",
        "    else:\n",
        "        img_path = os.path.join(data_dir, \"Deforested\", img_rel)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(\"Missing:\", img_path)\n",
        "        continue\n",
        "\n",
        "    feat = extract_features(img_path)\n",
        "    X.append(feat)\n",
        "    y.append(row['BinaryLabel'])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\" Features extracted\")\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Unique binary labels:\", np.unique(y))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrQa9TP58P8-",
        "outputId": "5b381957-3c51-4614-b733-e3699ec25fa7"
      },
      "id": "qrQa9TP58P8-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using subset size: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2268139720.py:20: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Features extracted\n",
            "Feature matrix shape: (2000, 1280)\n",
            "Labels shape: (2000,)\n",
            "Unique binary labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "clf_stage1 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf_stage1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf_stage1.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o81YAEhCEn-9",
        "outputId": "b51e2640-ccc5-410b-ca67-299962e1b442"
      },
      "id": "o81YAEhCEn-9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9625\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.68      0.81        47\n",
            "           1       0.96      1.00      0.98       353\n",
            "\n",
            "    accuracy                           0.96       400\n",
            "   macro avg       0.98      0.84      0.89       400\n",
            "weighted avg       0.96      0.96      0.96       400\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 32  15]\n",
            " [  0 353]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#  Subtype classification (only on deforested)\n",
        "\n",
        "\n",
        "# Filter only deforested samples\n",
        "mask_deforested = (y == 1)   # binary label = 1 means deforested\n",
        "X_def = X[mask_deforested]\n",
        "y_def = df.loc[mask_deforested, \"Label\"].values\n",
        "\n",
        "print(\"Deforested feature matrix shape:\", X_def.shape)\n",
        "print(\"Subtype labels shape:\", y_def.shape)\n",
        "print(\"Unique subtypes:\", np.unique(y_def))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_def, y_def, test_size=0.2, random_state=42, stratify=y_def\n",
        ")\n",
        "\n",
        "# Train Random Forest (multi-class)\n",
        "clf_stage2 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf_stage2.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf_stage2.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Stage-2 Accuracy:\", acc)\n",
        "\n",
        "print(\"\\nStage-2 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nStage-2 Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVvozg2HE92y",
        "outputId": "6305b0e9-1f74-4c3b-b26d-70b29fce0b95"
      },
      "id": "dVvozg2HE92y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deforested feature matrix shape: (1764, 1280)\n",
            "Subtype labels shape: (1764,)\n",
            "Unique subtypes: [0 2 3 4 5 6 7 8 9]\n",
            "Stage-2 Accuracy: 0.8611898016997167\n",
            "\n",
            "Stage-2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88        48\n",
            "           2       0.88      0.84      0.86        44\n",
            "           3       0.78      0.83      0.81        35\n",
            "           4       0.90      0.92      0.91        38\n",
            "           5       0.86      0.83      0.85        30\n",
            "           6       0.84      0.68      0.75        31\n",
            "           7       0.89      0.93      0.91        43\n",
            "           8       0.82      0.74      0.78        38\n",
            "           9       0.93      0.93      0.93        46\n",
            "\n",
            "    accuracy                           0.86       353\n",
            "   macro avg       0.86      0.85      0.85       353\n",
            "weighted avg       0.86      0.86      0.86       353\n",
            "\n",
            "\n",
            "Stage-2 Confusion Matrix:\n",
            "[[46  0  0  0  1  0  0  0  1]\n",
            " [ 0 37  1  0  1  1  1  1  2]\n",
            " [ 0  0 29  1  0  2  1  2  0]\n",
            " [ 1  0  0 35  0  0  2  0  0]\n",
            " [ 2  2  0  0 25  1  0  0  0]\n",
            " [ 3  2  1  2  0 21  1  1  0]\n",
            " [ 0  1  1  1  0  0 40  0  0]\n",
            " [ 4  0  5  0  1  0  0 28  0]\n",
            " [ 0  0  0  0  1  0  0  2 43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Reuse your pretrained feature extractor\n",
        "def extract_features(img_path, base_model):\n",
        "    img = image.load_img(img_path, target_size=(128,128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = base_model.predict(x, verbose=0)\n",
        "    return features.flatten().reshape(1, -1)\n",
        "\n",
        "# Pipeline function\n",
        "def predict_pipeline(img_path, base_model, clf_stage1, clf_stage2, subtype_mapping):\n",
        "    # Extract features\n",
        "    feat = extract_features(img_path, base_model)\n",
        "\n",
        "    # Stage 1: Forest vs. Deforested\n",
        "    stage1_pred = clf_stage1.predict(feat)[0]\n",
        "    if stage1_pred == 0:\n",
        "        return \"Forest\"\n",
        "    else:\n",
        "        # Stage 2: Which type of deforested\n",
        "        subtype_pred = clf_stage2.predict(feat)[0]\n",
        "        subtype_name = subtype_mapping.get(subtype_pred, f\"Subtype-{subtype_pred}\")\n",
        "        return f\"Deforested → {subtype_name}\"\n",
        "\n",
        "# Mapping numeric labels → class names\n",
        "subtype_mapping = {\n",
        "    0: \"Residential\",\n",
        "    2: \"Industrial\",\n",
        "    3: \"Pasture\",\n",
        "    4: \"River\",\n",
        "    5: \"Highway\",\n",
        "    6: \"SeaLake\",\n",
        "    7: \"PermanentCrop\",\n",
        "    8: \"HerbaceousVegetation\",\n",
        "    9: \"AnnualCrop\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "3mNCqoFks5h_"
      },
      "id": "3mNCqoFks5h_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# If not already present\n",
        "if 'BinaryLabel' not in df.columns:\n",
        "    df['BinaryLabel'] = df['ClassName'].apply(lambda x: 0 if x == \"Forest\" else 1)\n",
        "\n",
        "# Only deforested rows (Stage-2 classes)\n",
        "sub_df = df[df['BinaryLabel'] == 1].copy()\n",
        "\n",
        "# Show unique (Label, ClassName) pairs\n",
        "pairs = sub_df[['Label', 'ClassName']].drop_duplicates().sort_values('Label')\n",
        "print(\"Unique Label→ClassName pairs:\\n\", pairs.to_string(index=False))\n",
        "\n",
        "# Check for any conflicts (a label mapping to multiple names)\n",
        "conflicts = pairs.groupby('Label')['ClassName'].nunique()\n",
        "if (conflicts > 1).any():\n",
        "    print(\" Conflict detected in labels:\", conflicts[conflicts > 1])\n",
        "\n",
        "# Build mapping dict\n",
        "subtype_mapping = pairs.drop_duplicates('Label').set_index('Label')['ClassName'].to_dict()\n",
        "print(\"\\nFinal mapping dict:\", subtype_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unt0jim2LSID",
        "outputId": "3ab90288-66fc-4e7e-c824-759424f822ad"
      },
      "id": "Unt0jim2LSID",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Label→ClassName pairs:\n",
            "  Label            ClassName\n",
            "     0           AnnualCrop\n",
            "     2 HerbaceousVegetation\n",
            "     3              Highway\n",
            "     4           Industrial\n",
            "     5              Pasture\n",
            "     6        PermanentCrop\n",
            "     7          Residential\n",
            "     8                River\n",
            "     9              SeaLake\n",
            "\n",
            "Final mapping dict: {0: 'AnnualCrop', 2: 'HerbaceousVegetation', 3: 'Highway', 4: 'Industrial', 5: 'Pasture', 6: 'PermanentCrop', 7: 'Residential', 8: 'River', 9: 'SeaLake'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "7_N53Sv94K-B"
      },
      "id": "7_N53Sv94K-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "test_img1= \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/Deforested/Residential/Residential_2.jpg\"\n",
        "test_img2= \"/content/drive/MyDrive/Colab Notebooks/EuroSAT/Deforested/Industrial/Industrial_9.jpg\"\n",
        "\n",
        "result = predict_pipeline(test_img1, base_model, clf_stage1, clf_stage2, subtype_mapping)\n",
        "print(\"Prediction:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHC5lfAMGM62",
        "outputId": "7ae18b83-31bd-416f-eeec-aa9cd0859e9b"
      },
      "id": "UHC5lfAMGM62",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Deforested → Residential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(clf_stage1, \"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\")\n",
        "joblib.dump(clf_stage2, \"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\")\n",
        "\n",
        "print(\"✅ Models saved as clf_stage1.pkl and clf_stage2.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32LvPhYGbdM",
        "outputId": "ac8bc20a-4032-413c-c98c-eeb48d7c8a15"
      },
      "id": "W32LvPhYGbdM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Models saved as clf_stage1.pkl and clf_stage2.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if file exists\n",
        "print(os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\"))\n",
        "print(os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\"))\n",
        "\n",
        "# List contents of folder\n",
        "!ls -lh \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMOSJIxwJirZ",
        "outputId": "955d4122-ce0c-4a6f-a200-a3bc1cd2be4d"
      },
      "id": "pMOSJIxwJirZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "total 15M\n",
            "-rw------- 1 root root 1.6M Sep  1 16:48  clf_stage1.pkl\n",
            "-rw------- 1 root root  13M Sep  1 16:48  clf_stage2.pkl\n",
            "-rw------- 1 root root  14K Aug 30 13:45  deforesration_Detect.py\n",
            "-rw------- 1 root root  24K Sep  1 16:48 'Deforestion Random forest.ipynb'\n",
            "drwx------ 4 root root 4.0K Aug 30 05:37  EuroSAT\n",
            "-rw------- 1 root root 2.8K Sep  1 15:22  predict_app.py\n",
            "-rw------- 1 root root 1.2K Aug 30 13:21  Untitled0.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install streamlit\n",
        "# import streamlit as st\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from PIL import Image\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "# import joblib   # if you want to save/load your models\n",
        "\n",
        "# # -------------------------\n",
        "# # Load pretrained CNN\n",
        "# # -------------------------\n",
        "# base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# # Load trained classifiers (after you save them with joblib.dump)\n",
        "# # clf_stage1 = joblib.load(\"clf_stage1.pkl\")\n",
        "# # clf_stage2 = joblib.load(\"clf_stage2.pkl\")\n",
        "\n",
        "# # For demo – assuming you already have them in memory\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# clf_stage1 = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/clf_stage1.pkl\")\n",
        "# clf_stage2 = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/clf_stage2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "# # Mapping (make sure to use your actual mapping dictionary)\n",
        "# subtype_mapping = {\n",
        "#     0: \"AnnualCrop\",\n",
        "#     2: \"HerbaceousVegetation\",\n",
        "#     3: \"Industrial\",\n",
        "#     4: \"Pasture\",\n",
        "#     5: \"PermanentCrop\",\n",
        "#     6: \"Residential\",\n",
        "#     7: \"River\",\n",
        "#     8: \"SeaLake\",\n",
        "#     9: \"Highway\"\n",
        "# }\n",
        "\n",
        "# # -------------------------\n",
        "# # Feature extraction function\n",
        "# # -------------------------\n",
        "# def extract_features(img):\n",
        "#     img = img.resize((128, 128))   # same as training\n",
        "#     x = image.img_to_array(img)\n",
        "#     x = np.expand_dims(x, axis=0)\n",
        "#     x = preprocess_input(x)\n",
        "#     features = base_model.predict(x, verbose=0)\n",
        "#     return features.flatten()\n",
        "\n",
        "# # -------------------------\n",
        "# # Prediction pipeline\n",
        "# # -------------------------\n",
        "# def predict_pipeline(uploaded_img):\n",
        "#     # Extract features\n",
        "#     features = extract_features(uploaded_img).reshape(1, -1)\n",
        "\n",
        "#     # Stage-1: Forest vs Deforested\n",
        "#     stage1_pred = clf_stage1.predict(features)[0]\n",
        "\n",
        "#     if stage1_pred == 0:\n",
        "#         return \"🌲 Forest\"\n",
        "#     else:\n",
        "#         # Stage-2: Subtype classification\n",
        "#         subtype_pred = clf_stage2.predict(features)[0]\n",
        "#         subtype_name = subtype_mapping.get(subtype_pred, \"Unknown\")\n",
        "#         return f\"🌾 Deforested → {subtype_name}\"\n",
        "\n",
        "# # -------------------------\n",
        "# # Streamlit UI\n",
        "# # -------------------------\n",
        "# st.set_page_config(page_title=\"Deforestation Classifier\", page_icon=\"🌍\")\n",
        "# st.title(\"🛰️ Deforestation Detection\")\n",
        "# st.write(\"Upload a satellite image to classify whether it's **Forest** or **Deforested**, and if deforested → subtype.\")\n",
        "\n",
        "# uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# if uploaded_file is not None:\n",
        "#     img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "#     st.image(img, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "#     if st.button(\"🔍 Predict\"):\n",
        "#         result = predict_pipeline(img)\n",
        "#         st.success(f\"Prediction: {result}\")\n"
      ],
      "metadata": {
        "id": "1skNLsQYNYWu"
      },
      "id": "1skNLsQYNYWu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "# streamlit run predict_app.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjvlG98gNhq8",
        "outputId": "a0080811-8ebe-4553-8a3f-2e114878f8e3"
      },
      "id": "gjvlG98gNhq8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hA0kdiQdOA95"
      },
      "id": "hA0kdiQdOA95",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}